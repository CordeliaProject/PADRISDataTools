{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhuertas\\AppData\\Local\\Temp\\ipykernel_10484\\1404452101.py:8: DtypeWarning: Columns (3,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lab = pd.read_csv(r\"U:\\Estudis\\B52_CORDELIA\\Dades\\PADRIS\\D1_BD_PADRIS_regicor\\AP_Laboratoris.csv\", sep = \"|\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.patterns import patterns_common_words, numeric_patterns, unit_patterns\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "lab = pd.read_csv(r\"U:\\Estudis\\B52_CORDELIA\\Dades\\PADRIS\\D1_BD_PADRIS_regicor\\AP_Laboratoris.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab[\"lab_resultat\"] = lab[\"lab_resultat\"].fillna(\"nocalc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7825021"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_typos(df):\n",
    "    \"\"\"Initial data cleaning by removing typographical errors and extraneous characters from the result values.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Apply the cleaning steps to the specified column\n",
    "    df[\"clean_result\"] = df[\"lab_resultat\"].apply(lambda x: re.sub(r'[!#$&\\'();?@_`{|}~\"\\[\\]]', '', x))  # Remove special characters\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^=|=$', '', x))  # Remove leading and trailing equal signs\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^\\s+|\\s+$', '', x))  # Remove leading/trailing spaces\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^\\t+|\\t+$', '', x))  # Remove leading/trailing tabs\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clear_typos(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_extra_variables(df, patterns_common_words, numeric_patterns, report=True):\n",
    "    \"\"\"Cleans df['clean_result'] by handling flags, units, and interpretative comments.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Ensure 'comentari' column exists:\n",
    "    if 'comentari' not in df.columns:\n",
    "        df['comentari'] = pd.NA\n",
    "\n",
    "    def add_cleaning_comment(mask, comment):\n",
    "        \"\"\"Helper function to add a cleaning comment.\"\"\"\n",
    "        # Only update rows where the comment is not already present\n",
    "        df.loc[mask, 'comentari'] = df.loc[mask, 'comentari'].apply(\n",
    "            lambda x: f\"{x}, {comment}\".strip(', ') if pd.notna(x) and comment not in x else comment if pd.isna(x) else x\n",
    "        )\n",
    "\n",
    "    # Step 1: Handle interpretative flags (positive, negative, normal, etc.)\n",
    "    for flag, patterns in patterns_common_words.items():\n",
    "        for pattern in patterns:\n",
    "            # Use str.extract to directly capture matching groups\n",
    "            mask_literal = df['clean_result'].str.contains(pattern, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found\n",
    "\n",
    "            # Update the cleaning_comments column for affected rows\n",
    "            add_cleaning_comment(mask_literal, 'literal')\n",
    "\n",
    "            # Apply the replacement to the clean_result column only for rows that match the pattern\n",
    "            df.loc[mask_literal, 'clean_result'] = flag\n",
    "\n",
    "    # Step 2: Handle units and flags adjacent to numbers\n",
    "    adjacent_units1 = r'^(' + numeric_patterns['n1'] + r')\\s*(' + numeric_patterns['units']  + r')$'\n",
    "    adjacent_units2 = r'^(' + numeric_patterns['units'] + r')\\s*(' + numeric_patterns['n1'] + r')$'\n",
    "\n",
    "    # Case 1: Units after the result\n",
    "    mask_units_after = df['clean_result'].str.contains(adjacent_units1, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found.\n",
    "    unit_extracted = df.loc[mask_units_after, 'clean_result'].str.extract(adjacent_units1) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_units_after, 'units') # Add a comment to the 'comentari' column.\n",
    "    df.loc[mask_units_after, 'clean_result'] = df.loc[mask_units_after, 'clean_result'].str.replace(\n",
    "        adjacent_units1, r'\\1', flags=re.IGNORECASE, regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string.\n",
    "    \n",
    "    # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_units_after, 'unitat_mesura'] = unit_extracted[2] # Assign the third group of the extracted string to the 'unitat_mesura' column.\n",
    "\n",
    "    # Case 2: Units before the result\n",
    "    mask_units_before = df['clean_result'].str.contains(adjacent_units2, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found.\n",
    "    unit_extracted = df.loc[mask_units_before, 'clean_result'].str.extract(adjacent_units2) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_units_before, 'units') # Add a comment to the 'comentari' column.\n",
    "    df.loc[mask_units_before, 'clean_result'] = df.loc[mask_units_before, 'clean_result'].str.replace(\n",
    "        adjacent_units2, r'\\2', flags=re.IGNORECASE, regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string\n",
    "    \n",
    "    # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_units_before, 'unitat_mesura'] = unit_extracted[0]\n",
    "\n",
    "    # Step 3: Handle positive\n",
    "    for sign, _ in [(\"\\\\+\", \"positive\")]:\n",
    "        pattern = rf\"^{sign}\\s*({numeric_patterns['n1']})$\" # Define the pattern to match.\n",
    "        mask_sign = df['clean_result'].str.contains(pattern, na=False, regex=True) # Filter dataframe to only include rows where the pattern is found.\n",
    "        add_cleaning_comment(mask_sign, 'flag') # Add a comment to the 'comentari' column.\n",
    "        df.loc[mask_sign, 'clean_result'] = df.loc[mask_sign, 'clean_result'].str.replace(\n",
    "            pattern, r'\\1', regex=True\n",
    "        ) # Replace the matched string with the first group of the extracted string.\n",
    "\n",
    "    # Step 4: Handle percent\n",
    "    percent_pattern = rf\"^({numeric_patterns['n1']}) *(%)$\" # Define the pattern to match.\n",
    "    mask_percent = df['clean_result'].str.contains(percent_pattern, na=False, regex=True) # Filter dataframe to only include rows where the pattern is found.\n",
    "    percent_result = df.loc[mask_percent, 'clean_result'].str.extract(percent_pattern) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_percent, 'percent')\n",
    "    df.loc[mask_percent, 'clean_result'] = df.loc[mask_percent, 'clean_result'].str.replace(\n",
    "        percent_pattern, r'\\1', regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string.\n",
    "     # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_percent, 'unitat_mesura'] = percent_result[2]\n",
    "\n",
    "    # Step 5: Handle exponents\n",
    "    exponent_pattern = rf\"^({numeric_patterns['n1']})({numeric_patterns['exponent']})$\"\n",
    "    mask_exponent = df['clean_result'].str.contains(exponent_pattern, na=False, regex=True)\n",
    "    add_cleaning_comment(mask_exponent, 'exponents')\n",
    "    df.loc[mask_exponent, 'clean_result'] = df.loc[mask_exponent, 'clean_result'].str.replace(\n",
    "        exponent_pattern, r'\\1', regex=True\n",
    "    )\n",
    "    \n",
    "    # Clean up stray characters from exponents\n",
    "    df['clean_result'] = df['clean_result'].str.replace(r\"[\\*\\^]\", \"\", regex=True)\n",
    "\n",
    "    # Reporting\n",
    "    if report:\n",
    "        flagged_records = df['comentari'].notna().sum()\n",
    "        flagged_percent = flagged_records / len(df) * 100 if len(df) > 0 else 0\n",
    "        print(f\"{flagged_records} records flagged ({flagged_percent:.2f}% of total).\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357280 records flagged (4.57% of total).\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*match groups.*\")\n",
    "test2 = handle_extra_variables(test, patterns_common_words, numeric_patterns, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_numeric_results(df,  numeric_patterns, report=False):\n",
    "    \"\"\" Classifies numeric results into n1, n2, n3, and n4 scales based on patterns.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Ensure 'comentari' column exists:\n",
    "    if 'num_type' not in df.columns:\n",
    "        df['num_type'] = pd.NA\n",
    "\n",
    "    # Step 1: Assign n1 scale type for inequality patterns\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n1']}$\"), \"n1\")\n",
    "    \n",
    "    # Step 2: Assign n2 scale type for inequality patterns\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n2']}$\"), \"n2\")\n",
    "    \n",
    "    # Step 3: Assign n3 for range patterns separated by hypens\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n3']}$\"), \"n3\")\n",
    "\n",
    "    # Step 4: Assign n4 for titer patterns. When a number is divided by a second integer. Separated by \":\" or \"/\"\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n4']}$\"), \"n4\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = classify_numeric_results(test2,  numeric_patterns, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_number(value):\n",
    "    \"\"\" Standardizes the format of numeric values in the lab data.\"\"\"\n",
    "    if not isinstance(value, str):\n",
    "        return value  # If value is not a string, return it as is\n",
    "\n",
    "    # Step 1: Apply specific rules for Spanish-formatted numbers.\n",
    "    # Mask 1: Remove commas in strings with two or more commas\n",
    "    if re.search(r'\\d{1,3},0{3},0{3}', value):  # Matches '1,000,000' or similar\n",
    "        value = re.sub(r',', '', value)\n",
    "\n",
    "    # Mask 2: Remove commas in '10,000' or '100,000'\n",
    "    elif re.search(r'10{1,2},000', value):  # Matches '10,000' or '100,000'\n",
    "        value = re.sub(r',', '', value)\n",
    "\n",
    "    # Mask 3: Adjust values like ',1234' to '0,1234'\n",
    "    elif re.search(r'^,\\d{1,4}$', value):  # Matches ',1234'\n",
    "        value = re.sub(r'^,', '0,', value)\n",
    "\n",
    "    # Step 2: Transform commas to dots for decimal numbers (e.g., '1,23' -> '1.23')\n",
    "    value = re.sub(r',', '.', value)\n",
    "\n",
    "    # Step 3: Remove leading zeros unless it's a decimal (e.g., '01.23' -> '1.23')\n",
    "    value = re.sub(r'^0+(\\d)', r'\\1', value)  # Remove leading zeros before digits\n",
    "    value = re.sub(r'^0+(\\.\\d+)', r'0\\1', value)  # Ensure '0.' is kept for decimals\n",
    "\n",
    "    # Step 4: Round to 3 decimals\n",
    "    if '.' in value:\n",
    "        value = re.sub(r'(\\.\\d{3})\\d+', r'\\1', value)  # Keep up to 3 decimal places\n",
    "        value = value.rstrip('0').rstrip('.')  # Remove trailing zeros and possibly the decimal point\n",
    "\n",
    "    return value\n",
    "\n",
    "def standardize_n2(value):\n",
    "    \"\"\" Standardizes the format of numeric values of num_type n2 in the lab data.\"\"\"\n",
    "    # Ensure there are no spaces in the value\n",
    "    value = re.sub(r\" \", \"\", value)\n",
    "\n",
    "    # Step 1: Extract the non numerical parts:\n",
    "    non_numerical = re.findall(\"[<>=]\", value)\n",
    "    numerical = re.sub(\"[<>=]\", \"\", value)\n",
    "\n",
    "    # Step 2: Standardize numbers\n",
    "    standardized_value = list(standardize_number(numerical))\n",
    "\n",
    "    # Add all together and generate the result\n",
    "    result = non_numerical + standardized_value\n",
    "    result = \"\".join(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def standardize_numeric_results(df, report=False):\n",
    "    \"\"\" Standardizes the lab data by cleaning the result values and assigning scale types.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def report_num_type(df, num_type):\n",
    "        \"\"\" Function to report the number and percentage of records assigned to a given scale type\"\"\"\n",
    "        # Filter records by scale type\n",
    "        scale_records = df[df['num_type'] == num_type]\n",
    "        \n",
    "        # Calculate the number of records\n",
    "        scale_records_n = len(scale_records)\n",
    "        \n",
    "        # Calculate the percentage of total records\n",
    "        total_n_records = len(df)\n",
    "        scale_records_percent = (scale_records_n / total_n_records * 100) if total_n_records else np.nan\n",
    "        \n",
    "        # Report the results\n",
    "        print(f\"{scale_records_n} result records of scale type '{num_type}' ({scale_records_percent:.2f}%).\")\n",
    "\n",
    "    # Step 1: Harmonize n1 results.\n",
    "    mask_n1 = df['num_type'] == 'n1' # Create a mask for the conditions\n",
    "    df.loc[mask_n1, 'clean_result'] = df.loc[mask_n1, 'clean_result'].apply(standardize_number) # Apply transformation using the mask (vectorized)\n",
    "\n",
    "    # Step 2: Harmonize n2, n3, n4 results.\n",
    "    # Create the mask for the conditions\n",
    "    num_types = ['n2', 'n3', 'n4']\n",
    "\n",
    "    for num_type in num_types:\n",
    "        mask = df['num_type'] == num_type\n",
    "        # Apply transformation using the mask (vectorized)\n",
    "        df.loc[mask, 'clean_result'] = df.loc[mask, 'clean_result'].apply(\n",
    "            lambda x: re.sub(r\" \", \"\", re.sub(r\"/\", \":\", x))\n",
    "        )\n",
    "        if num_type == 'n2':\n",
    "            # Apply the specific transformation for n2\n",
    "            df.loc[mask, 'clean_result'] = df.loc[mask, 'clean_result'].apply(standardize_n2)\n",
    "    \n",
    "    # Step 3: Check that n3 results are plausible: first number must be lower than second.\n",
    "    mask_n3 = df['num_type'] == 'n3'\n",
    "    # Extract the first and second numbers using vectorized string methods for 'n3' rows\n",
    "    df.loc[mask_n3, 'first_number'] = df.loc[mask_n3, 'clean_result'].str.extract(r\"^([0-9]+)-\")[0].apply(standardize_number)\n",
    "    df.loc[mask_n3, 'second_number'] = df.loc[mask_n3, 'clean_result'].str.extract(r\"-([0-9]+)$\")[0].apply(standardize_number)\n",
    "\n",
    "    # Convert the extracted values to numeric, replacing non-numeric entries with NaN\n",
    "    df['first_number'] = pd.to_numeric(df['first_number'], errors='coerce')\n",
    "    df['second_number'] = pd.to_numeric(df['second_number'], errors='coerce')\n",
    "\n",
    "    # Remove scale type where the second number is lower than the first\n",
    "    df.loc[mask_n3 & (df['second_number'] < df['first_number']), 'num_type'] = pd.NA\n",
    "\n",
    "    # Drop temporary columns 'first_number' and 'second_number'\n",
    "    df = df.drop(columns=['first_number', 'second_number'])\n",
    "\n",
    "    \n",
    "    # Reporting numbers of records assigned to each number type\n",
    "    if report:\n",
    "        for num_type in ['n1', 'n2', 'n3', 'n4']:\n",
    "            report_num_type(df, num_type)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = standardize_numeric_results(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_unit(df, unit_patterns, report = False):\n",
    "    \"\"\" Standardizes the format of units in the lab data.\"\"\"\n",
    "    df = df.copy()\n",
    "    total_n_records = len(df)\n",
    "    # Ensure \"clean_unit\" column exists.\n",
    "    if \"clean_unit\" not in df.columns:\n",
    "        df[\"clean_unit\"] = df[\"unitat_mesura\"]\n",
    "    \n",
    "    # For each unit in the unit_patterns dictionary, if it is found in the \"unitat_mesura\" column, replace it with the corresponding key.\n",
    "    for unit, pattern in unit_patterns.items():\n",
    "        mask = df[\"unitat_mesura\"].str.contains(pattern, na = False, flags = re.IGNORECASE, regex = True) # Filter dataframe to only include rows where the pattern is found.\n",
    "        df.loc[mask, \"clean_unit\"] = unit # Replace the unit with the standardized unit.\n",
    "\n",
    "    if report:\n",
    "        n_units_standardized = len(df[df[\"unitat_mesura\"] != df[\"clean_unit\"]]) # Calculate the number of rows with standardized units.\n",
    "        scale_records_percent = (n_units_standardized / total_n_records * 100) if total_n_records else np.nan # Calculate the percentage of total records.\n",
    "        print(f\"{n_units_standardized} rows with standardized units ({scale_records_percent:.2f}%).\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5892472 rows with standardized units (75.30%).\n"
     ]
    }
   ],
   "source": [
    "test5 = standardize_unit(test4, unit_patterns, report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codi_p</th>\n",
       "      <th>Any_prova</th>\n",
       "      <th>Data_prova</th>\n",
       "      <th>peticio_id</th>\n",
       "      <th>lab_prova_c</th>\n",
       "      <th>lab_prova</th>\n",
       "      <th>lab_resultat</th>\n",
       "      <th>unitat_mesura</th>\n",
       "      <th>ref_min</th>\n",
       "      <th>ref_max</th>\n",
       "      <th>clean_result</th>\n",
       "      <th>comentari</th>\n",
       "      <th>num_type</th>\n",
       "      <th>clean_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10254</td>\n",
       "      <td>2010</td>\n",
       "      <td>17/08/2010</td>\n",
       "      <td>81705546520</td>\n",
       "      <td>H11740</td>\n",
       "      <td>BASÒFILS;C.NOM.</td>\n",
       "      <td>0</td>\n",
       "      <td>K/mcL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>10^3/µl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7314</td>\n",
       "      <td>2011</td>\n",
       "      <td>01/08/2011</td>\n",
       "      <td>80100100846</td>\n",
       "      <td>H11740</td>\n",
       "      <td>BASÒFILS;C.NOM.</td>\n",
       "      <td>0</td>\n",
       "      <td>K/mcL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>10^3/µl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8871</td>\n",
       "      <td>2008</td>\n",
       "      <td>17/03/2008</td>\n",
       "      <td>31774972</td>\n",
       "      <td>H11740</td>\n",
       "      <td>BASÒFILS;C.NOM.</td>\n",
       "      <td>0</td>\n",
       "      <td>K/mcL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>10^3/µl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241</td>\n",
       "      <td>2008</td>\n",
       "      <td>13/05/2008</td>\n",
       "      <td>51354073</td>\n",
       "      <td>H11740</td>\n",
       "      <td>BASÒFILS;C.NOM.</td>\n",
       "      <td>0</td>\n",
       "      <td>K/mcL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>10^3/µl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11405</td>\n",
       "      <td>2010</td>\n",
       "      <td>20/04/2010</td>\n",
       "      <td>42005701677</td>\n",
       "      <td>H11740</td>\n",
       "      <td>BASÒFILS;C.NOM.</td>\n",
       "      <td>0</td>\n",
       "      <td>K/mcL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>10^3/µl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825016</th>\n",
       "      <td>9255</td>\n",
       "      <td>2016</td>\n",
       "      <td>01/09/2016</td>\n",
       "      <td>90105546769</td>\n",
       "      <td>H11840</td>\n",
       "      <td>BASÒFILS;FR.NOM. (leucòcits)</td>\n",
       "      <td>,5</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825017</th>\n",
       "      <td>10726</td>\n",
       "      <td>2016</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>110400100272</td>\n",
       "      <td>H11840</td>\n",
       "      <td>BASÒFILS;FR.NOM. (leucòcits)</td>\n",
       "      <td>,5</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825018</th>\n",
       "      <td>7691</td>\n",
       "      <td>2017</td>\n",
       "      <td>13/12/2017</td>\n",
       "      <td>121305613907</td>\n",
       "      <td>H11840</td>\n",
       "      <td>BASÒFILS;FR.NOM. (leucòcits)</td>\n",
       "      <td>,5</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825019</th>\n",
       "      <td>11051</td>\n",
       "      <td>2017</td>\n",
       "      <td>04/10/2017</td>\n",
       "      <td>100405547798</td>\n",
       "      <td>H11840</td>\n",
       "      <td>BASÒFILS;FR.NOM. (leucòcits)</td>\n",
       "      <td>,5</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825020</th>\n",
       "      <td>1608</td>\n",
       "      <td>2016</td>\n",
       "      <td>19/01/2016</td>\n",
       "      <td>11905492936</td>\n",
       "      <td>H11840</td>\n",
       "      <td>BASÒFILS;FR.NOM. (leucòcits)</td>\n",
       "      <td>,5</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>n1</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7825021 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         codi_p  Any_prova  Data_prova    peticio_id lab_prova_c  \\\n",
       "0         10254       2010  17/08/2010   81705546520      H11740   \n",
       "1          7314       2011  01/08/2011   80100100846      H11740   \n",
       "2          8871       2008  17/03/2008      31774972      H11740   \n",
       "3          3241       2008  13/05/2008      51354073      H11740   \n",
       "4         11405       2010  20/04/2010   42005701677      H11740   \n",
       "...         ...        ...         ...           ...         ...   \n",
       "7825016    9255       2016  01/09/2016   90105546769      H11840   \n",
       "7825017   10726       2016  04/11/2016  110400100272      H11840   \n",
       "7825018    7691       2017  13/12/2017  121305613907      H11840   \n",
       "7825019   11051       2017  04/10/2017  100405547798      H11840   \n",
       "7825020    1608       2016  19/01/2016   11905492936      H11840   \n",
       "\n",
       "                            lab_prova lab_resultat unitat_mesura ref_min  \\\n",
       "0                     BASÒFILS;C.NOM.            0         K/mcL     NaN   \n",
       "1                     BASÒFILS;C.NOM.            0         K/mcL     NaN   \n",
       "2                     BASÒFILS;C.NOM.            0         K/mcL     NaN   \n",
       "3                     BASÒFILS;C.NOM.            0         K/mcL     NaN   \n",
       "4                     BASÒFILS;C.NOM.            0         K/mcL     NaN   \n",
       "...                               ...          ...           ...     ...   \n",
       "7825016  BASÒFILS;FR.NOM. (leucòcits)           ,5             %       0   \n",
       "7825017  BASÒFILS;FR.NOM. (leucòcits)           ,5             %       0   \n",
       "7825018  BASÒFILS;FR.NOM. (leucòcits)           ,5             %       0   \n",
       "7825019  BASÒFILS;FR.NOM. (leucòcits)           ,5             %       0   \n",
       "7825020  BASÒFILS;FR.NOM. (leucòcits)           ,5             %       0   \n",
       "\n",
       "        ref_max clean_result comentari num_type clean_unit  \n",
       "0           NaN            0      <NA>       n1    10^3/µl  \n",
       "1           NaN            0      <NA>       n1    10^3/µl  \n",
       "2           NaN            0      <NA>       n1    10^3/µl  \n",
       "3           NaN            0      <NA>       n1    10^3/µl  \n",
       "4           NaN            0      <NA>       n1    10^3/µl  \n",
       "...         ...          ...       ...      ...        ...  \n",
       "7825016       2          0.5      <NA>       n1          %  \n",
       "7825017       2          0.5      <NA>       n1          %  \n",
       "7825018       2          0.5      <NA>       n1          %  \n",
       "7825019       2          0.5      <NA>       n1          %  \n",
       "7825020       2          0.5      <NA>       n1          %  \n",
       "\n",
       "[7825021 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
