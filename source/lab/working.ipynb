{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhuertas\\AppData\\Local\\Temp\\ipykernel_21300\\1404452101.py:8: DtypeWarning: Columns (3,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lab = pd.read_csv(r\"U:\\Estudis\\B52_CORDELIA\\Dades\\PADRIS\\D1_BD_PADRIS_regicor\\AP_Laboratoris.csv\", sep = \"|\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.patterns import patterns_common_words, numeric_patterns, unit_patterns\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "lab = pd.read_csv(r\"U:\\Estudis\\B52_CORDELIA\\Dades\\PADRIS\\D1_BD_PADRIS_regicor\\AP_Laboratoris.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab[\"lab_resultat\"] = lab[\"lab_resultat\"].fillna(\"nocalc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7825021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_typos(df):\n",
    "    \"\"\"Initial data cleaning by removing typographical errors and extraneous characters from the result values.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Apply the cleaning steps to the specified column\n",
    "    df[\"clean_result\"] = df[\"lab_resultat\"].apply(lambda x: re.sub(r'[!#$&\\'();?@_`{|}~\"\\[\\]]', '', x))  # Remove special characters\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^=|=$', '', x))  # Remove leading and trailing equal signs\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^\\s+|\\s+$', '', x))  # Remove leading/trailing spaces\n",
    "    df[\"clean_result\"] = df[\"clean_result\"].apply(lambda x: re.sub(r'^\\t+|\\t+$', '', x))  # Remove leading/trailing tabs\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clear_typos(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_extra_variables(df, patterns_common_words, numeric_patterns, report=True):\n",
    "    \"\"\"Cleans df['clean_result'] by handling flags, units, and interpretative comments.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Ensure 'comentari' column exists:\n",
    "    if 'comentari' not in df.columns:\n",
    "        df['comentari'] = pd.NA\n",
    "\n",
    "    def add_cleaning_comment(mask, comment):\n",
    "        \"\"\"Helper function to add a cleaning comment.\"\"\"\n",
    "        # Only update rows where the comment is not already present\n",
    "        df.loc[mask, 'comentari'] = df.loc[mask, 'comentari'].apply(\n",
    "            lambda x: f\"{x}, {comment}\".strip(', ') if pd.notna(x) and comment not in x else comment if pd.isna(x) else x\n",
    "        )\n",
    "\n",
    "    # Step 1: Handle interpretative flags (positive, negative, normal, etc.)\n",
    "    for flag, patterns in patterns_common_words.items():\n",
    "        for pattern in patterns:\n",
    "            # Use str.extract to directly capture matching groups\n",
    "            mask_literal = df['clean_result'].str.contains(pattern, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found\n",
    "\n",
    "            # Update the cleaning_comments column for affected rows\n",
    "            add_cleaning_comment(mask_literal, 'literal')\n",
    "\n",
    "            # Apply the replacement to the clean_result column only for rows that match the pattern\n",
    "            df.loc[mask_literal, 'clean_result'] = flag\n",
    "\n",
    "    # Step 2: Handle units and flags adjacent to numbers\n",
    "    adjacent_units1 = r'^(' + numeric_patterns['n1'] + r')\\s*(' + numeric_patterns['units']  + r')$'\n",
    "    adjacent_units2 = r'^(' + numeric_patterns['units'] + r')\\s*(' + numeric_patterns['n1'] + r')$'\n",
    "\n",
    "    # Case 1: Units after the result\n",
    "    mask_units_after = df['clean_result'].str.contains(adjacent_units1, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found.\n",
    "    unit_extracted = df.loc[mask_units_after, 'clean_result'].str.extract(adjacent_units1) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_units_after, 'units') # Add a comment to the 'comentari' column.\n",
    "    df.loc[mask_units_after, 'clean_result'] = df.loc[mask_units_after, 'clean_result'].str.replace(\n",
    "        adjacent_units1, r'\\1', flags=re.IGNORECASE, regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string.\n",
    "    \n",
    "    # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_units_after, 'unitat_mesura'] = unit_extracted[2] # Assign the third group of the extracted string to the 'unitat_mesura' column.\n",
    "\n",
    "    # Case 2: Units before the result\n",
    "    mask_units_before = df['clean_result'].str.contains(adjacent_units2, na=False, flags=re.IGNORECASE, regex=True) #Filter dataframe to only include rows where the pattern is found.\n",
    "    unit_extracted = df.loc[mask_units_before, 'clean_result'].str.extract(adjacent_units2) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_units_before, 'units') # Add a comment to the 'comentari' column.\n",
    "    df.loc[mask_units_before, 'clean_result'] = df.loc[mask_units_before, 'clean_result'].str.replace(\n",
    "        adjacent_units2, r'\\2', flags=re.IGNORECASE, regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string\n",
    "    \n",
    "    # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_units_before, 'unitat_mesura'] = unit_extracted[0]\n",
    "\n",
    "    # Step 3: Handle positive\n",
    "    for sign, _ in [(\"\\\\+\", \"positive\")]:\n",
    "        pattern = rf\"^{sign}\\s*({numeric_patterns['n1']})$\" # Define the pattern to match.\n",
    "        mask_sign = df['clean_result'].str.contains(pattern, na=False, regex=True) # Filter dataframe to only include rows where the pattern is found.\n",
    "        add_cleaning_comment(mask_sign, 'flag') # Add a comment to the 'comentari' column.\n",
    "        df.loc[mask_sign, 'clean_result'] = df.loc[mask_sign, 'clean_result'].str.replace(\n",
    "            pattern, r'\\1', regex=True\n",
    "        ) # Replace the matched string with the first group of the extracted string.\n",
    "\n",
    "    # Step 4: Handle percent\n",
    "    percent_pattern = rf\"^({numeric_patterns['n1']}) *(%)$\" # Define the pattern to match.\n",
    "    mask_percent = df['clean_result'].str.contains(percent_pattern, na=False, regex=True) # Filter dataframe to only include rows where the pattern is found.\n",
    "    percent_result = df.loc[mask_percent, 'clean_result'].str.extract(percent_pattern) # Extract parts from the matched string.\n",
    "    add_cleaning_comment(mask_percent, 'percent')\n",
    "    df.loc[mask_percent, 'clean_result'] = df.loc[mask_percent, 'clean_result'].str.replace(\n",
    "        percent_pattern, r'\\1', regex=True\n",
    "    ) # Replace the matched string with the first group of the extracted string.\n",
    "     # Fix: Use str.extract to get the correct unit for unitat_mesura\n",
    "    df.loc[mask_percent, 'unitat_mesura'] = percent_result[2]\n",
    "\n",
    "    # Step 5: Handle exponents\n",
    "    exponent_pattern = rf\"^({numeric_patterns['n1']})({numeric_patterns['exponent']})$\"\n",
    "    mask_exponent = df['clean_result'].str.contains(exponent_pattern, na=False, regex=True)\n",
    "    add_cleaning_comment(mask_exponent, 'exponents')\n",
    "    df.loc[mask_exponent, 'clean_result'] = df.loc[mask_exponent, 'clean_result'].str.replace(\n",
    "        exponent_pattern, r'\\1', regex=True\n",
    "    )\n",
    "    \n",
    "    # Clean up stray characters from exponents\n",
    "    df['clean_result'] = df['clean_result'].str.replace(r\"[\\*\\^]\", \"\", regex=True)\n",
    "\n",
    "    # Reporting\n",
    "    if report:\n",
    "        flagged_records = df['comentari'].notna().sum()\n",
    "        flagged_percent = flagged_records / len(df) * 100 if len(df) > 0 else 0\n",
    "        print(f\"{flagged_records} records flagged ({flagged_percent:.2f}% of total).\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357280 records flagged (4.57% of total).\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*match groups.*\")\n",
    "test2 = handle_extra_variables(test, patterns_common_words, numeric_patterns, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_numeric_results(df,  numeric_patterns, report=False):\n",
    "    \"\"\" Classifies numeric results into n1, n2, n3, and n4 scales based on patterns.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Ensure 'comentari' column exists:\n",
    "    if 'num_type' not in df.columns:\n",
    "        df['num_type'] = pd.NA\n",
    "\n",
    "    # Step 1: Assign n1 scale type for inequality patterns\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n1']}$\"), \"n1\")\n",
    "    \n",
    "    # Step 2: Assign n2 scale type for inequality patterns\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n2']}$\"), \"n2\")\n",
    "    \n",
    "    # Step 3: Assign n3 for range patterns separated by hypens\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n3']}$\"), \"n3\")\n",
    "\n",
    "    # Step 4: Assign n4 for titer patterns. When a number is divided by a second integer. Separated by \":\" or \"/\"\n",
    "    df['num_type'] = df['num_type'].where(\n",
    "        ~df['clean_result'].str.match(f\"^{numeric_patterns['n4']}$\"), \"n4\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = classify_numeric_results(test2,  numeric_patterns, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_number(value):\n",
    "    \"\"\" Standardizes the format of numeric values in the lab data.\"\"\"\n",
    "    if not isinstance(value, str):\n",
    "        return value  # If value is not a string, return it as is\n",
    "\n",
    "    # Step 1: Apply specific rules for Spanish-formatted numbers.\n",
    "    # Mask 1: Remove commas in strings with two or more commas\n",
    "    if re.search(r'\\d{1,3},0{3},0{3}', value):  # Matches '1,000,000' or similar\n",
    "        value = re.sub(r',', '', value)\n",
    "\n",
    "    # Mask 2: Remove commas in '10,000' or '100,000'\n",
    "    elif re.search(r'10{1,2},000', value):  # Matches '10,000' or '100,000'\n",
    "        value = re.sub(r',', '', value)\n",
    "\n",
    "    # Mask 3: Adjust values like ',1234' to '0,1234'\n",
    "    if value.startswith(','):\n",
    "        value = '0' + value  # Convert to 0,xxxx format\n",
    "\n",
    "    # Step 2: Transform commas to dots for decimal numbers (e.g., '1,23' -> '1.23')\n",
    "    value = re.sub(r',', '.', value)\n",
    "\n",
    "    # Step 3: Remove leading zeros unless it's a decimal (e.g., '01.23' -> '1.23')\n",
    "    value = re.sub(r'^0+(\\d)', r'\\1', value)  # Remove leading zeros before digits\n",
    "    value = re.sub(r'^0+(\\.\\d+)', r'0\\1', value)  # Ensure '0.' is kept for decimals\n",
    "\n",
    "    # Step 4: Round to 3 decimals\n",
    "    if '.' in value:\n",
    "        value = re.sub(r'(\\.\\d{3})\\d+', r'\\1', value)  # Keep up to 3 decimal places\n",
    "        value = value.rstrip('0').rstrip('.')  # Remove trailing zeros and possibly the decimal point\n",
    "\n",
    "    return value\n",
    "\n",
    "def standardize_n2(value):\n",
    "    \"\"\" Standardizes the format of numeric values of num_type n2 in the lab data.\"\"\"\n",
    "    # Ensure there are no spaces in the value\n",
    "    value = re.sub(r\" \", \"\", value)\n",
    "\n",
    "    # Step 1: Extract the non numerical parts:\n",
    "    non_numerical = re.findall(\"[<>=]\", value)\n",
    "    numerical = re.sub(\"[<>=]\", \"\", value)\n",
    "\n",
    "    # Step 2: Standardize numbers\n",
    "    standardized_value = list(standardize_number(numerical))\n",
    "\n",
    "    # Add all together and generate the result\n",
    "    result = non_numerical + standardized_value\n",
    "    result = \"\".join(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def standardize_numeric_results(df, report=False):\n",
    "    \"\"\" Standardizes the lab data by cleaning the result values and assigning scale types.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def report_num_type(df, num_type):\n",
    "        \"\"\" Function to report the number and percentage of records assigned to a given scale type\"\"\"\n",
    "        # Filter records by scale type\n",
    "        scale_records = df[df['num_type'] == num_type]\n",
    "        \n",
    "        # Calculate the number of records\n",
    "        scale_records_n = len(scale_records)\n",
    "        \n",
    "        # Calculate the percentage of total records\n",
    "        total_n_records = len(df)\n",
    "        scale_records_percent = (scale_records_n / total_n_records * 100) if total_n_records else np.nan\n",
    "        \n",
    "        # Report the results\n",
    "        print(f\"{scale_records_n} result records of scale type '{num_type}' ({scale_records_percent:.2f}%).\")\n",
    "\n",
    "    # Step 1: Harmonize n1 results.\n",
    "    mask_n1 = df['num_type'] == 'n1' # Create a mask for the conditions\n",
    "    df.loc[mask_n1, 'clean_result'] = df.loc[mask_n1, 'clean_result'].apply(standardize_number) # Apply transformation using the mask (vectorized)\n",
    "\n",
    "    # Step 2: Harmonize n2, n3, n4 results.\n",
    "    # Create the mask for the conditions\n",
    "    num_types = ['n2', 'n3', 'n4']\n",
    "\n",
    "    for num_type in num_types:\n",
    "        mask = df['num_type'] == num_type\n",
    "        # Apply transformation using the mask (vectorized)\n",
    "        df.loc[mask, 'clean_result'] = df.loc[mask, 'clean_result'].apply(\n",
    "            lambda x: re.sub(r\" \", \"\", re.sub(r\"/\", \":\", x))\n",
    "        )\n",
    "        if num_type == 'n2':\n",
    "            # Apply the specific transformation for n2\n",
    "            df.loc[mask, 'clean_result'] = df.loc[mask, 'clean_result'].apply(standardize_n2)\n",
    "    \n",
    "    # Step 3: Check that n3 results are plausible: first number must be lower than second.\n",
    "    mask_n3 = df['num_type'] == 'n3'\n",
    "    # Extract the first and second numbers using vectorized string methods for 'n3' rows\n",
    "    df.loc[mask_n3, 'first_number'] = df.loc[mask_n3, 'clean_result'].str.extract(r\"^([0-9]+)-\")[0].apply(standardize_number)\n",
    "    df.loc[mask_n3, 'second_number'] = df.loc[mask_n3, 'clean_result'].str.extract(r\"-([0-9]+)$\")[0].apply(standardize_number)\n",
    "\n",
    "    # Convert the extracted values to numeric, replacing non-numeric entries with NaN\n",
    "    df['first_number'] = pd.to_numeric(df['first_number'], errors='coerce')\n",
    "    df['second_number'] = pd.to_numeric(df['second_number'], errors='coerce')\n",
    "\n",
    "    # Remove scale type where the second number is lower than the first\n",
    "    df.loc[mask_n3 & (df['second_number'] < df['first_number']), 'num_type'] = pd.NA\n",
    "\n",
    "    # Drop temporary columns 'first_number' and 'second_number'\n",
    "    df = df.drop(columns=['first_number', 'second_number'])\n",
    "\n",
    "    \n",
    "    # Reporting numbers of records assigned to each number type\n",
    "    if report:\n",
    "        for num_type in ['n1', 'n2', 'n3', 'n4']:\n",
    "            report_num_type(df, num_type)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = standardize_numeric_results(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_unit(df, unit_patterns, report = False):\n",
    "    \"\"\" Standardizes the format of units in the lab data.\"\"\"\n",
    "    df = df.copy()\n",
    "    total_n_records = len(df)\n",
    "    # Ensure \"clean_unit\" column exists.\n",
    "    if \"clean_unit\" not in df.columns:\n",
    "        df[\"clean_unit\"] = df[\"unitat_mesura\"]\n",
    "        df['comentari_unitat'] = pd.NA\n",
    "    \n",
    "    # For each unit in the unit_patterns dictionary, if it is found in the \"unitat_mesura\" column, replace it with the corresponding key.\n",
    "    for unit, pattern in unit_patterns.items():\n",
    "        mask = (df[\"clean_unit\"].str.contains(pattern, na = False, flags = re.IGNORECASE, regex = True) & df['comentari_unitat'].isna()) # Filter dataframe to only include rows where the pattern is found.\n",
    "        df.loc[mask, \"clean_unit\"] = unit # Replace the unit with the standardized unit.\n",
    "        df.loc[mask, \"comentari_unitat\"] = \"done\" # Add a comment to the 'comentari_unitat' column.\n",
    "\n",
    "    if report:\n",
    "        n_units_standardized = len(df[df['comentari_unitat'] == \"done\"]) # Calculate the number of rows with standardized units.\n",
    "        scale_records_percent = (n_units_standardized / total_n_records * 100) if total_n_records else np.nan # Calculate the percentage of total records.\n",
    "        print(f\"{n_units_standardized} rows with standardized units ({scale_records_percent:.2f}%).\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6474623 rows with standardized units (82.74%).\n"
     ]
    }
   ],
   "source": [
    "test5 = standardize_unit(test4, unit_patterns, report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_test = test5[(test5['comentari_unitat'] != \"done\")].sort_values(\"unitat_mesura\")[['unitat_mesura']].drop_duplicates()\n",
    "pattern_test.to_csv(r\"U:\\Estudis\\B52_CORDELIA\\Analisis\\test_unitats.csv\", index = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
